# Predicci√≥n de Lluvias usando XGBoost con el conjunto de datos Australianos

Este proyecto reproduce y compara los resultados del paper  
**‚ÄúAn AI-Enabled ensemble method for rainfall forecasting using LSTM‚Äù**,  
usando √∫nicamente **XGBoost** sobre el dataset p√∫blico *Rain in Australia*.

---

## üí° Definici√≥n del problema

*"Predecir la lluvia con precisi√≥n es un desaf√≠o en contextos de alta variabilidad clim√°tica como Australia. Este trabajo buscar√° abordar ese problema mediante el uso de algoritmos de aprendizaje autom√°tico aplicados a un conjunto de datos meteorol√≥gicos hist√≥ricos de Australia."*


## üéØ Objetivos
| Tipo | Descripci√≥n |
|------|-------------|
| **General** | Dise√±ar un modelo de predicci√≥n de lluvia basado en XGBoost. |
| **Espec√≠ficos** | 1. Identificar variables relevantes.<br>2. Ajustar hiperpar√°metros y balanceo.<br>3. Evaluar con accuracy, precision, recall y F1.<br>4. Comparar con el estado del arte publicado. |

## ‚å®Ô∏è Implementaci√≥n
Predecir con precisi√≥n si llover√° al d√≠a siguiente en cualquiera de las 49 estaciones meteorol√≥gicas australianas registradas (2008-2017).


## ‚öôÔ∏è Pipeline resumido
1. **Carga & limpieza**  
   - Conversi√≥n de fechas, estaciones, direcciones a grados.  
   - Imputaci√≥n multivariante (`IterativeImputer`).  
2. **Preprocesado**  
   - One-Hot para categ√≥ricas, escalado z-score para num√©ricas.  
3. **Modelos XGBoost**  
   - `Modelo_A` optimiza precisi√≥n.<br>
   - `Modelo_B` optimiza recall.  
   - Ensamble lineal \((0.5\,A + 0.5\,B)\).  
4. **Selecci√≥n de umbral** sobre el conjunto de validaci√≥n.  
5. **M√©tricas en test** (con datos desbalanceados reales).  

## üìä Resultados actuales

| Clase                 | Precision | Recall | F1-score | Support |
|----------------------|-----------|--------|----------|---------|
| **0 (No llover√° - Paper)**   | 0.89      | 0.96   | 0.93     | 18238   |
| **1 (S√≠ llover√° - Paper)**   | 0.96      | 0.89   | 0.92     | 18714   |  
|                      |           |        |          |         |
| **0 (No llover√° - Modelo propio)**   | 0.902     | 0.914  | 0.908    | 22064   | 
| **1 (S√≠ llover√° - Modelo propio)**   | 0.687     | 0.657  | 0.672    |  6375   |

| M√©trica global       | Paper      | Nuestro modelo |
|----------------------|------------|-----------------|
| **Accuracy**         | 0.92       | 0.856           |
| **Macro Avg (F1)**   | 0.92       | 0.790           |
| **Weighted Avg (F1)**| 0.92       | 0.855           |

> *Nota:* El paper eval√∫a sobre un conjunto de prueba balanceado con SMOTE, lo que eleva artificialmente las m√©tricas.  
> El test propio mantiene la distribuci√≥n original para un escenario m√°s realista.

## üß™ T√©cnicas exploradas sin mejora significativa
Durante el proceso se implementaron varias estrategias con el objetivo de mejorar la predicci√≥n de la clase minoritaria ("s√≠ llover√°"). Sin embargo, no presentaron resultados significantes comparados al tiempo que llev√≥ su ejecuci√≥n:

1. **GridSearchCV para optimizaci√≥n exhaustiva de hiperpar√°metros**
Se probaron m√∫ltiples combinaciones en dos clasificadores XGBoost con validaci√≥n cruzada. La b√∫squeda tom√≥ varias horas y solo se consigui√≥ una leve mejora en F1-score (~0.5%).

2. **Modelo stacking (meta-modelo de regresi√≥n log√≠stica sobre dos clasificadores)**
Aunque se increment√≥ ligeramente el recall (~5%), se redujo la precision y el resultado global fue inferior en F1 y accuracy respecto al resultado incial base.

Esas pruebas fueron √∫tiles para delimitar la complejidad necesaria y validar que el modelo actual logra un buen compromiso entre rendimiento y costo computacional.

## üìà Pr√≥ximos pasos
1. **Reevaluar el balanceo en el conjunto de prueba**  
   Aunque SMOTE se aplic√≥ correctamente al conjunto de entrenamiento, el paper tambi√©n balancea el test set, lo cual eleva artificialmente m√©tricas como recall y F1.  
   ‚Üí *Decidir si se replica este enfoque para comparaci√≥n directa o mantener un test realista.*

2. **Optimizar el umbral de decisi√≥n para la clase "lluvia"**  
   Actualmente se usa un ensamble con ajuste de umbral √≥ptimo seg√∫n F1. A√∫n as√≠, se puede:  
   - Explorar la **optimizaci√≥n multiobjetivo** (precisi√≥n *vs* recall).  
   - Incorporar m√©tricas de costos asim√©tricos (por ejemplo, penalizar m√°s los falsos negativos).

3. **Probar t√©cnicas avanzadas de balanceo de clases**  
   - `SMOTE-Tomek`para una generaci√≥n de muestras m√°s robusta.  
   - `scale_pos_weight` din√°mico durante el entrenamiento.  

4. **Reintroducir variables eliminadas (p.ej., `Cloud9am`, `Cloud3pm`)**  
   Estas columnas fueron descartadas por alto porcentaje de valores nulos. Sin embargo, la imputaci√≥n m√∫ltiple (p. ej., `IterativeImputer`) puede permitir recuperar informaci√≥n √∫til para la predicci√≥n.

---
